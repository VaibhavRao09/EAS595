{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TO DO##\n",
    "\n",
    "# Please fill in the blanks following the comments in the cells. You will be using 20 newsgroup dataset for this project, \n",
    "#which is already fetched in the first cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data set - training data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can check the target names (categories) and some data files by following commands.\n",
    "twenty_train.target_names #prints all the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3])) #prints first line of the first data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just to see all parameters of twenty_train loaded from fetch_20newsgroups Train dataset\n",
    "#twenty_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 130107)\n"
     ]
    }
   ],
   "source": [
    "##TO DO##\n",
    "\n",
    "# The first step toward obtaining tf-idf feature  is defining the count vector. Fill in the blank below \n",
    "#and your count vector shape for the training collection should be like the output shown below.\n",
    "#Extracting features from text files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#fill with your code using CountVectorizer function is here\n",
    "# vectorize means we turn non-numerical data into an array of numbers\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_train_Count = count_vectorizer.fit_transform(twenty_train.data)\n",
    "print(X_train_Count.shape)\n",
    "#X_train_Count.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TO DO##\n",
    "\n",
    "# extract the TF-IDF feature using TfidfTransformer and the shape of the training fecture vectors \n",
    "#look like the output shown below.\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#fill with your code using TfidfTransformer function is here\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_Count)\n",
    "X_train_tfidf.shape\n",
    "#X_train_tfidf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TO DO##\n",
    "\n",
    "# Machine Learning\n",
    "# Example usage: Training Naive Bayes (NB) classifier on training data.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
    "#fill with your code using another classifier discussed in class\n",
    "\n",
    "# Example usage: Training Bernoulli(NB) classifier on training data.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf2 = BernoulliNB().fit(X_train_tfidf, twenty_train.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7532, 130107)\n",
      "BernoulliNB performance: 0.6307753584705258\n",
      "MultinomialNB performance: 0.7738980350504514\n"
     ]
    }
   ],
   "source": [
    "''' Not Specifically required. Just for Understanding !!!!! '''\n",
    "## Just A different method to understand the advantage of pipeline!!!\n",
    "import numpy as np\n",
    "# Performance of NB Classifier\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "#print(twenty_test.keys())\n",
    "#print(len(twenty_test['data']))\n",
    "#print(len(twenty_test['target']))\n",
    "X_test_count = count_vectorizer.transform(twenty_test.data)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_count)\n",
    "print(X_test_tfidf.shape)\n",
    "print('BernoulliNB performance: {}'.format(clf2.score(X_test_tfidf, twenty_test.target)))\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "print('MultinomialNB performance: {}'.format(np.mean(predicted == twenty_test.target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TO DO##\n",
    "\n",
    "# Here we are just building a pipeline: We can write less code and do all of the above, by building a pipeline as follows:\n",
    "# The names ‘vect’ , ‘tfidf’ and ‘clf’ are arbitrary but will be used later.\n",
    "# We will be using the 'text_clf' going forward. Since I use MultinomialNB() for this example, I have specified that as my classifier,\n",
    "# you can replace the name of 'clf' with your chosen classifier in another cell below\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf2 = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf2', BernoulliNB())])\n",
    "\n",
    "text_clf2 = text_clf2.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "text_clf3 = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf3', LogisticRegression())])\n",
    "\n",
    "text_clf3 = text_clf3.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7738980350504514"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance of NB Classifier\n",
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TO DO##\n",
    "# Show the Performance of your classifier here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6307753584705258"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted2 = text_clf2.predict(twenty_test.data)\n",
    "np.mean(predicted2 == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8274030801911842"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted3 = text_clf3.predict(twenty_test.data)\n",
    "np.mean(predicted3 == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
